# Limitations and Enhancements in Genomic Language Models ğŸ§¬
##### Open Source Code, Data and modelsğŸ§¾
This repository provides the source code, datasets, and pre-trained models used in our research to advance genomic language modeling. It also includes detailed instructions on how to replicate our experiments, download data and models, and explore additional functionalities. For more details, refer to our preprint on bioRxiv: [Limitations and Enhancements in Genomic Language Models: Dynamic Selection Approach](https://www.biorxiv.org/content/10.1101/2024.11.25.624002v1)

## Quich Start  ğŸš€
### 1. Clone the repository
```bash
git clone https://github.com/Jacob-S-Qiu/glm_dynamic_selection.git
cd glm_dynamic_selection
```
### 2. Install dependencies
Make sure Python 3.9+ is installed, and use the following command to install required packages:
```bash
pip install -r requirements.txt
```
### 3. Download MEME-Suite
Please follow the [official guide](https://meme-suite.org/meme/meme_5.5.6/doc/install.html?man_type=web)

### 4. Usage
- **All experimental files, including data files and model weight files**, are hosted on [Google Drive](https://drive.google.com/drive/folders/1tX7eobxMzt2fH2RZM7mxxmqnDmkR0ulb?usp=sharing). You can download individual files or directly download the **entire project** from Google Drive, which includes the entire repository with code, data, and weights.

- **To train a model**, ensure you have `accelerate` installed and run the following commands:
  ```bash
  pip install accelerate>=0.26.0
  accelerate launch train.py
  ```
  
- **To download the configurations for the three models mentioned in the paper**, use the following links:
  - Hyena: [LongSafari/hyenadna-medium-160k-seqlen-hf](https://huggingface.co/LongSafari/hyenadna-medium-160k-seqlen-hf)
  - NTv2: [InstaDeepAI/nucleotide-transformer-v2-500m-multi-species](https://huggingface.co/InstaDeepAI/nucleotide-transformer-v2-500m-multi-species)
  - CD-GPT: [TencentAI4S/CD-GPT](https://github.com/TencentAI4S/CD-GPT)
 
After the environment is set up, you can start using the repository for various tasks such as data processing, training, or model evaluation.

## Citing Our Work ğŸ“
```plaintext
@article{qiu2024genomic,
  title={Limitations and Enhancements in Genomic Language Models: Dynamic Selection Approach},
  author={Shibo Qiu},
  journal={bioRxiv},
  year={2024},
  doi={10.1101/2024.11.25.624002}
}
```
## License ğŸ“š
This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## directory structure ğŸ 
```plaintext
â”œâ”€â”€ all_models_weights 
â”‚   â”œâ”€â”€ cd_long_base_best_model.pth
â”‚   â”œâ”€â”€ cd_long_dynamic_best_model.pth
â”‚   â”œâ”€â”€ cd_long_err_base_best_model.pth
â”‚   â”œâ”€â”€ cd_long_err_dynamic_best_model.pth
â”‚   â”œâ”€â”€ cd_short_base_best_model.pth
â”‚   â”œâ”€â”€ cd_short_dynamic_best_model.pth
â”‚   â”œâ”€â”€ hy_long_base_best_model.bin
â”‚   â”œâ”€â”€ hy_long_dynamic_best_model.bin
â”‚   â”œâ”€â”€ hy_long_err_base_bast_model.bin
â”‚   â”œâ”€â”€ hy_long_err_dynamic_best_model.bin
â”‚   â”œâ”€â”€ hy_short_base_best_model.bin
â”‚   â”œâ”€â”€ hy_short_dynamic_best_model.bin
â”‚   â”œâ”€â”€ nt_long_base_best_model.safetensors
â”‚   â”œâ”€â”€ nt_long_dynamic_best_model.safetensors
â”‚   â”œâ”€â”€ nt_long_err_base_best_model.safetensors
â”‚   â”œâ”€â”€ nt_long_err_dynamic_best_model.safetensors
â”‚   â”œâ”€â”€ nt_short_base_best_model.safetensors
â”‚   â””â”€â”€ nt_short_dynamic_best_model.safetensors
â”œâ”€â”€ data_long_sequence # Long sequence of the whole process of the experiment
â”‚   â”œâ”€â”€ data-analysis
â”‚   â”‚   â”œâ”€â”€ 3model_result # sequence data
â”‚   â”‚   â”‚   â”œâ”€â”€ 3model_all_correct.fasta
â”‚   â”‚   â”‚   â”œâ”€â”€ 3model_all_correct.pt
â”‚   â”‚   â”‚   â”œâ”€â”€ 3model_all_wrong.fasta
â”‚   â”‚   â”‚   â”œâ”€â”€ 3model_all_wrong.pt
â”‚   â”‚   â”‚   â”œâ”€â”€ 3model_have_1_correct.fasta
â”‚   â”‚   â”‚   â”œâ”€â”€ 3model_have_1_correct.pt
â”‚   â”‚   â”‚   â”œâ”€â”€ 3model_have_2_correct.fasta
â”‚   â”‚   â”‚   â””â”€â”€ 3model_have_2_correct.pt
â”‚   â”‚   â”œâ”€â”€ 3model_result_compare # download and just open, you could view the sequence analysis page
â”‚   â”‚   â”‚   â”œâ”€â”€ 3model_1_correct_feature_MAST.htm
â”‚   â”‚   â”‚   â”œâ”€â”€ 3model_1_correct_feature_MEME.htm
â”‚   â”‚   â”‚   â”œâ”€â”€ 3model_2_correct_feature_MAST.htm
â”‚   â”‚   â”‚   â”œâ”€â”€ 3model_2_correct_feature_MEME.htm
â”‚   â”‚   â”‚   â”œâ”€â”€ 3model_all_correct_feature_MAST.htm
â”‚   â”‚   â”‚   â”œâ”€â”€ 3model_all_correct_feature_MEME.html
â”‚   â”‚   â”‚   â”œâ”€â”€ 3model_all_wrong_feature_MAST.htm
â”‚   â”‚   â”‚   â””â”€â”€ 3model_all_wrong_feature_MEME.htm
â”‚   â”‚   â”œâ”€â”€ data # all data are available
â”‚   â”‚   â”‚   â”œâ”€â”€ CDgpt_2_8754.pt
â”‚   â”‚   â”‚   â”œâ”€â”€ Hyena_602.pt
â”‚   â”‚   â”‚   â””â”€â”€ NTv2_240.pt
â”‚   â”‚   â”œâ”€â”€ step1_similiar.ipynb
â”‚   â”‚   â””â”€â”€ step2_feature_analysis.ipynb
â”‚   â”œâ”€â”€ test.pt
â”‚   â”œâ”€â”€ train.pt
â”‚   â””â”€â”€ valid.pt
â”œâ”€â”€ experiment_long_sequence
â”‚   â”œâ”€â”€ base_models
â”‚   â”‚   â”œâ”€â”€ cdgpt
â”‚   â”‚   â”‚   â”œâ”€â”€ result
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ cdgpt_14590_test_results.pt
â”‚   â”‚   â”‚   â””â”€â”€ train&valid&eval
â”‚   â”‚   â”‚       â”œâ”€â”€ cd_e1_step1_train_on_dataset.py
â”‚   â”‚   â”‚       â”œâ”€â”€ cd_e1_step2_get_best_model.py
â”‚   â”‚   â”‚       â””â”€â”€ cd_e1_step3_get_features_from_best_model.py
â”‚   â”‚   â”œâ”€â”€ hyena
â”‚   â”‚   â”‚   â”œâ”€â”€ result
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ hyena_1053_test_feature_final.pt
â”‚   â”‚   â”‚   â””â”€â”€ train&valid&eval
â”‚   â”‚   â”‚       â”œâ”€â”€ hy_e1_step1_train.py
â”‚   â”‚   â”‚       â”œâ”€â”€ hy_e1_step2_get_best_model.py
â”‚   â”‚   â”‚       â””â”€â”€ hy_e1_step3_get_features.py
â”‚   â”‚   â”œâ”€â”€ ntv2
â”‚   â”‚   â”‚   â”œâ”€â”€ result
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ntv2_240_test_results.pt
â”‚   â”‚   â”‚   â””â”€â”€ train&valid&eval
â”‚   â”‚   â”‚       â”œâ”€â”€ nt_e1_step1_tokenize_dataset.py
â”‚   â”‚   â”‚       â”œâ”€â”€ nt_e1_step2_train.py
â”‚   â”‚   â”‚       â”œâ”€â”€ nt_e1_step3_get_best_model.py
â”‚   â”‚   â”‚       â””â”€â”€ nt_e1_step4_get_features.py
â”‚   â”‚   â”œâ”€â”€ step5_3model_result
â”‚   â”‚   â”‚   â”œâ”€â”€ 3model_all_correct.fasta
â”‚   â”‚   â”‚   â”œâ”€â”€ 3model_all_correct.pt
â”‚   â”‚   â”‚   â”œâ”€â”€ 3model_all_wrong.fasta
â”‚   â”‚   â”‚   â”œâ”€â”€ 3model_all_wrong.pt
â”‚   â”‚   â”‚   â”œâ”€â”€ 3model_have_1_correct.fasta
â”‚   â”‚   â”‚   â”œâ”€â”€ 3model_have_1_correct.pt
â”‚   â”‚   â”‚   â”œâ”€â”€ 3model_have_2_correct.fasta
â”‚   â”‚   â”‚   â””â”€â”€ 3model_have_2_correct.pt
â”‚   â”‚   â”œâ”€â”€ step5_3model_result_similiar_compare.ipynb # Compare the differences between the models
â”‚   â”‚   â”œâ”€â”€ step6_3model_confidence_analysis.ipynb # Analyze the confidence of the model
â”‚   â”‚   â”œâ”€â”€ step6_merged_file
â”‚   â”‚   â”‚   â”œâ”€â”€ merged_model_test_data_results.pt
â”‚   â”‚   â”‚   â”œâ”€â”€ merged_model_train_data_results.pt 
â”‚   â”‚   â”‚   â””â”€â”€ merged_model_valid_data_results.pt
â”‚   â”‚   â”œâ”€â”€ step7_3model_result_fasta
â”‚   â”‚   â”‚   â”œâ”€â”€ 3model_all_correct.fasta
â”‚   â”‚   â”‚   â”œâ”€â”€ 3model_all_wrong.fasta
â”‚   â”‚   â”‚   â”œâ”€â”€ 3model_have_1_correct.fasta
â”‚   â”‚   â”‚   â””â”€â”€ 3model_have_2_correct.fasta
â”‚   â”‚   â”œâ”€â”€ step7_3model_sequence_make_fasta.ipynb # We need to use MEME, so we need a.fasta file
â”‚   â”‚   â”œâ”€â”€ step8_make_soft_labels_dataset.ipynb 
â”‚   â”‚   â””â”€â”€ step8_soft_labels_dataset
â”‚   â”‚       â”œâ”€â”€ merged_soft_label_and_models_prediction_test_dataset.pt
â”‚   â”‚       â”œâ”€â”€ merged_soft_label_and_models_prediction_train_dataset.pt 
â”‚   â”‚       â”œâ”€â”€ merged_soft_label_and_models_prediction_valid_dataset.pt
â”‚   â”‚       â”œâ”€â”€ soft_labels_test_dataset.pt
â”‚   â”‚       â”œâ”€â”€ soft_labels_train_dataset.pt 
â”‚   â”‚       â””â”€â”€ soft_labels_valid_dataset.pt
â”‚   â”œâ”€â”€ data
â”‚   â”‚   â”œâ”€â”€ test.pt
â”‚   â”‚   â”œâ”€â”€ train.pt 
â”‚   â”‚   â””â”€â”€ valid.pt
â”‚   â””â”€â”€ dynamic_models
â”‚       â”œâ”€â”€ cdgpt
â”‚       â”‚   â”œâ”€â”€ result
â”‚       â”‚   â”‚   â””â”€â”€ C7_e1_9000_result_feature.pt
â”‚       â”‚   â””â”€â”€ train&valid
â”‚       â”‚       â”œâ”€â”€ cd_e2_step1_train&get_best_model.py
â”‚       â”‚       â””â”€â”€ cd_e2_step2_get_features.py
â”‚       â”œâ”€â”€ hyena
â”‚       â”‚   â”œâ”€â”€ result
â”‚       â”‚   â”‚   â””â”€â”€ C7_hyena_e1_540_result_feature.pt
â”‚       â”‚   â””â”€â”€ train&valid
â”‚       â”‚       â”œâ”€â”€ hy_e2_step1_train.py
â”‚       â”‚       â”œâ”€â”€ hy_e2_step2_get_best_model.py
â”‚       â”‚       â””â”€â”€ hy_e2_step3_get_features.py
â”‚       â”œâ”€â”€ ntv2
â”‚       â”‚   â”œâ”€â”€ result
â”‚       â”‚   â”‚   â””â”€â”€ C7_ntv2_e1_380_result_feature.pt
â”‚       â”‚   â””â”€â”€ train&valid
â”‚       â”‚       â”œâ”€â”€ nt_e2_get_best_model.py
â”‚       â”‚       â”œâ”€â”€ nt_e2_step1_train.py
â”‚       â”‚       â””â”€â”€ nt_e2_step3_get_features.py
â”‚       â”œâ”€â”€ step9
â”‚       â”‚   â”œâ”€â”€ e2-cdgpt-result
â”‚       â”‚   â”‚   â”œâ”€â”€ cd_0_right_file.pt
â”‚       â”‚   â”‚   â”œâ”€â”€ .....(omit 14 files)
â”‚       â”‚   â”‚   â””â”€â”€ nt_1_wrong_file.pt
â”‚       â”‚   â”œâ”€â”€ e2-hyena-result
â”‚       â”‚   â”‚   â”œâ”€â”€ cd_0_right_file.pt
â”‚       â”‚   â”‚   â”œâ”€â”€ ......(omit 14 files)
â”‚       â”‚   â”‚   â””â”€â”€ nt_1_wrong_file.pt
â”‚       â”‚   â””â”€â”€ e2-ntv2-result
â”‚       â”‚       â”œâ”€â”€ cd_0_right_file.pt
â”‚       â”‚       â”œâ”€â”€ ......(omit 14 files)
â”‚       â”‚       â””â”€â”€ nt_1_wrong_file.pt
â”‚       â””â”€â”€ step9-result-data-processing.ipynb
â”œâ”€â”€ experiment_long_sequence_err
â”‚   â”œâ”€â”€ base_models
â”‚   â”‚   â”œâ”€â”€ cdgpt
â”‚   â”‚   â”‚   â”œâ”€â”€ result
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ cdgpt_c10_3036_test_results.pt
â”‚   â”‚   â”‚   â””â”€â”€ train&valid&eval
â”‚   â”‚   â”‚       â”œâ”€â”€ cd_e1_step1_train_on_dataset.py
â”‚   â”‚   â”‚       â”œâ”€â”€ cd_e1_step2_get_best_model.py
â”‚   â”‚   â”‚       â””â”€â”€ cd_e1_step3_get_features_from_best_model.py
â”‚   â”‚   â”œâ”€â”€ hyena
â”‚   â”‚   â”‚   â”œâ”€â”€ result
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ hyena_c10_690_test.pt
â”‚   â”‚   â”‚   â””â”€â”€ train&valid&eval
â”‚   â”‚   â”‚       â”œâ”€â”€ hy_e1_step1_train.py
â”‚   â”‚   â”‚       â”œâ”€â”€ hy_e1_step2_get_best_model.py
â”‚   â”‚   â”‚       â””â”€â”€ hy_e1_step3_get_features.py
â”‚   â”‚   â”œâ”€â”€ ntv2
â”‚   â”‚   â”‚   â”œâ”€â”€ result
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ntv2_c10_test_results.pt
â”‚   â”‚   â”‚   â””â”€â”€ train&valid&eval
â”‚   â”‚   â”‚       â”œâ”€â”€ nt_e1_step1_tokenize_dataset.py
â”‚   â”‚   â”‚       â”œâ”€â”€ nt_e1_step2_train.py
â”‚   â”‚   â”‚       â”œâ”€â”€ nt_e1_step3_get_best_model.py
â”‚   â”‚   â”‚       â””â”€â”€ nt_e1_step4_get_features.py
â”‚   â”‚   â”œâ”€â”€ step5_3model_result
â”‚   â”‚   â”‚   â”œâ”€â”€ 2model_all_correct_nt_cd.fasta
â”‚   â”‚   â”‚   â”œâ”€â”€ 2model_all_correct_nt_cd.htm
â”‚   â”‚   â”‚   â”œâ”€â”€ 2model_all_correct_nt_cd.pt
â”‚   â”‚   â”‚   â”œâ”€â”€ 2model_all_wrong_nt_cd.fasta
â”‚   â”‚   â”‚   â”œâ”€â”€ 2model_all_wrong_nt_cd.htm
â”‚   â”‚   â”‚   â”œâ”€â”€ 2model_all_wrong_nt_cd.pt
â”‚   â”‚   â”‚   â”œâ”€â”€ 3model_all_correct.pt
â”‚   â”‚   â”‚   â””â”€â”€ 3model_all_wrong.pt
â”‚   â”‚   â”œâ”€â”€ step5_3model_result_similiar_compare.ipynb
â”‚   â”‚   â”œâ”€â”€ step6_3model_confidence_analysis.ipynb
â”‚   â”‚   â”œâ”€â”€ step6_merged_file
â”‚   â”‚   â”‚   â”œâ”€â”€ merged_model_test_data.pt
â”‚   â”‚   â”‚   â”œâ”€â”€ merged_model_train_data.pt
â”‚   â”‚   â”‚   â””â”€â”€ merged_model_valid_data.pt
â”‚   â”‚   â”œâ”€â”€ step7_3model_result_fasta
â”‚   â”‚   â”‚   â”œâ”€â”€ 2model_all_correct_nt_cd.fasta
â”‚   â”‚   â”‚   â””â”€â”€ 2model_all_wrong_nt_cd.fasta
â”‚   â”‚   â”œâ”€â”€ step7_3model_sequence_make_fasta.ipynb
â”‚   â”‚   â”œâ”€â”€ step8_make_soft_labels_dataset.ipynb
â”‚   â”‚   â””â”€â”€ step8_soft_labels_dataset
â”‚   â”‚       â”œâ”€â”€ merged_soft_label_and_models_prediction_test_dataset.pt
â”‚   â”‚       â”œâ”€â”€ merged_soft_label_and_models_prediction_train_dataset.pt
â”‚   â”‚       â”œâ”€â”€ merged_soft_label_and_models_prediction_valid_dataset.pt
â”‚   â”‚       â”œâ”€â”€ soft_labels_test_dataset.pt
â”‚   â”‚       â”œâ”€â”€ soft_labels_train_dataset.pt
â”‚   â”‚       â””â”€â”€ soft_labels_valid_dataset.pt
â”‚   â”œâ”€â”€ data
â”‚   â”‚   â”œâ”€â”€ C10_cdgpt_1kbp_test_dataset.pt
â”‚   â”‚   â”œâ”€â”€ C10_cdgpt_1kbp_train_dataset.pt
â”‚   â”‚   â”œâ”€â”€ C10_cdgpt_1kbp_valid_dataset.pt
â”‚   â”‚   â”œâ”€â”€ C10_hyena_20kbp_test_dataset.pt
â”‚   â”‚   â”œâ”€â”€ C10_hyena_20kbp_train_dataset.pt
â”‚   â”‚   â”œâ”€â”€ C10_hyena_20kbp_valid_dataset.pt
â”‚   â”‚   â”œâ”€â”€ C10_ntv2_12kbp_test_dataset.pt
â”‚   â”‚   â”œâ”€â”€ C10_ntv2_12kbp_train_dataset.pt# this file is in google drive(too big)
â”‚   â”‚   â”œâ”€â”€ C10_ntv2_12kbp_valid_dataset.pt
â”‚   â”‚   â””â”€â”€ step1_get_DNA_from_Ensemble.ipynb
â”‚   â””â”€â”€ dynamic_models
â”‚       â”œâ”€â”€ cdgpt
â”‚       â”‚   â”œâ”€â”€ result
â”‚       â”‚   â”‚   â””â”€â”€ C11_cdgpt_e2_10200_result_feature.pt
â”‚       â”‚   â””â”€â”€ train&valid
â”‚       â”‚       â”œâ”€â”€ cd_e2_step1_train&get_best_model.py
â”‚       â”‚       â””â”€â”€ cd_e2_step2_get_features.py
â”‚       â”œâ”€â”€ hyena
â”‚       â”‚   â”œâ”€â”€ result
â”‚       â”‚   â”‚   â””â”€â”€ C11_hyena_e2_800_result_feature.pt
â”‚       â”‚   â””â”€â”€ train&valid
â”‚       â”‚       â”œâ”€â”€ hy_e2_step1_train.py
â”‚       â”‚       â”œâ”€â”€ hy_e2_step2_get_best_model.py
â”‚       â”‚       â””â”€â”€ hy_e2_step3_get_features.py
â”‚       â”œâ”€â”€ ntv2
â”‚       â”‚   â”œâ”€â”€ result
â”‚       â”‚   â”‚   â””â”€â”€ C7_ntv2_e1_380_result_feature.pt
â”‚       â”‚   â””â”€â”€ train&valid
â”‚       â”‚       â”œâ”€â”€ nt_e2_get_best_model.py
â”‚       â”‚       â”œâ”€â”€ nt_e2_step1_train.py
â”‚       â”‚       â””â”€â”€ nt_e2_step3_get_features.py
â”‚       â”œâ”€â”€ step9
â”‚       â”‚   â”œâ”€â”€ cdgpt-e2-result-data-analysis
â”‚       â”‚   â”‚   â”œâ”€â”€ cd_0_right_file.pt
â”‚       â”‚   â”‚   â”œâ”€â”€ ......(omit 14 files)
â”‚       â”‚   â”‚   â””â”€â”€ nt_1_wrong_file.pt
â”‚       â”‚   â”œâ”€â”€ hyena-e2-result-data-analysis
â”‚       â”‚   â”‚   â”œâ”€â”€ cd_0_right_file.pt
â”‚       â”‚   â”‚   â”œâ”€â”€ ......(omit 14 files)
â”‚       â”‚   â”‚   â””â”€â”€ nt_1_wrong_file.pt
â”‚       â”‚   â””â”€â”€ ntv2-e2-result-data-analysis
â”‚       â”‚       â”œâ”€â”€ cd_0_right_file.pt
â”‚       â”‚       â”œâ”€â”€ ......(omit 14 files)
â”‚       â”‚       â””â”€â”€ nt_1_wrong_sequences.fasta
â”‚       â””â”€â”€ step9-result-data-processing.ipynb
â”œâ”€â”€ experiment_short_sequence
â”‚   â”œâ”€â”€ base_models
â”‚   â”‚   â”œâ”€â”€ cdgpt
â”‚   â”‚   â”‚   â”œâ”€â”€ result
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ cdgpt_c12_human_enhancers_cohn_test_10420_results.pt
â”‚   â”‚   â”‚   â””â”€â”€ train&valid&eval
â”‚   â”‚   â”‚       â”œâ”€â”€ cd_e1_step1_train_on_dataset.py
â”‚   â”‚   â”‚       â”œâ”€â”€ cd_e1_step2_get_best_model.py
â”‚   â”‚   â”‚       â””â”€â”€ cd_e1_step3_get_features_from_best_model.py
â”‚   â”‚   â”œâ”€â”€ hyena
â”‚   â”‚   â”‚   â”œâ”€â”€ result
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ hyena_c12_e1_human_enhancers_cohn_test_120.pt
â”‚   â”‚   â”‚   â””â”€â”€ train&valid&eval
â”‚   â”‚   â”‚       â”œâ”€â”€ hy_e1_step1_train.py
â”‚   â”‚   â”‚       â”œâ”€â”€ hy_e1_step2_get_best_model.py
â”‚   â”‚   â”‚       â””â”€â”€ hy_e1_step3_get_features.py
â”‚   â”‚   â”œâ”€â”€ ntv2
â”‚   â”‚   â”‚   â”œâ”€â”€ result
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ntv2_c12_human-enhancers-cohn_test_results_200.pt
â”‚   â”‚   â”‚   â””â”€â”€ train&valid&eval
â”‚   â”‚   â”‚       â”œâ”€â”€ nt_e1_step1_tokenize_dataset.py
â”‚   â”‚   â”‚       â”œâ”€â”€ nt_e1_step2_train.py
â”‚   â”‚   â”‚       â”œâ”€â”€ nt_e1_step3_get_best_model.py
â”‚   â”‚   â”‚       â””â”€â”€ nt_e1_step4_get_features.py
â”‚   â”‚   â”œâ”€â”€ step5_3model_result
â”‚   â”‚   â”‚   â”œâ”€â”€ 3model_all_correct.pt
â”‚   â”‚   â”‚   â”œâ”€â”€ 3model_all_wrong.pt
â”‚   â”‚   â”‚   â”œâ”€â”€ 3model_have_1_correct.pt
â”‚   â”‚   â”‚   â””â”€â”€ 3model_have_2_correct.pt
â”‚   â”‚   â”œâ”€â”€ step5_3model_result_similiar_compare.ipynb
â”‚   â”‚   â”œâ”€â”€ step6_3model_confidence_analysis.ipynb
â”‚   â”‚   â”œâ”€â”€ step6_merged_file
â”‚   â”‚   â”‚   â”œâ”€â”€ merged_model_test_data.pt
â”‚   â”‚   â”‚   â””â”€â”€ merged_model_train_data.pt
â”‚   â”‚   â”œâ”€â”€ step7_3model_result_fasta
â”‚   â”‚   â”‚   â”œâ”€â”€ 3model_all_correct.fasta
â”‚   â”‚   â”‚   â”œâ”€â”€ 3model_all_wrong.fasta
â”‚   â”‚   â”‚   â”œâ”€â”€ 3model_have_1_correct.fasta
â”‚   â”‚   â”‚   â””â”€â”€ 3model_have_2_correct.fasta
â”‚   â”‚   â”œâ”€â”€ step7_3model_sequence_make_fasta.ipynb
â”‚   â”‚   â”œâ”€â”€ step8_make_soft_labels_dataset.ipynb
â”‚   â”‚   â””â”€â”€ step8_soft_labels_dataset
â”‚   â”‚       â”œâ”€â”€ merged_soft_label_and_models_prediction_test_dataset.pt
â”‚   â”‚       â”œâ”€â”€ merged_soft_label_and_models_prediction_train_dataset.pt
â”‚   â”‚       â”œâ”€â”€ step1_soft_labels_test_dataset.pt
â”‚   â”‚       â””â”€â”€ step1_soft_labels_train_dataset.pt
â”‚   â”œâ”€â”€ data
â”‚   â”‚   â”œâ”€â”€ dataset_summary.csv
â”‚   â”‚   â”œâ”€â”€ genomic_benchmark_datasets # benchmarks
â”‚   â”‚   â”‚   â”œâ”€â”€ test_demo_coding_vs_intergenomic_seqs.pt
â”‚   â”‚   â”‚   â”œâ”€â”€ test_demo_human_or_worm.pt
â”‚   â”‚   â”‚   â”œâ”€â”€ test_drosophila_enhancers_stark.pt
â”‚   â”‚   â”‚   â”œâ”€â”€ test_human_enhancers_cohn.pt
â”‚   â”‚   â”‚   â”œâ”€â”€ test_human_enhancers_ensembl.pt
â”‚   â”‚   â”‚   â”œâ”€â”€ test_human_ensembl_regulatory.pt
â”‚   â”‚   â”‚   â”œâ”€â”€ test_human_nontata_promoters.pt
â”‚   â”‚   â”‚   â”œâ”€â”€ test_human_ocr_ensembl.pt
â”‚   â”‚   â”‚   â”œâ”€â”€ train_demo_coding_vs_intergenomic_seqs.pt
â”‚   â”‚   â”‚   â”œâ”€â”€ train_demo_human_or_worm.pt
â”‚   â”‚   â”‚   â”œâ”€â”€ train_drosophila_enhancers_stark.pt
â”‚   â”‚   â”‚   â”œâ”€â”€ train_human_enhancers_cohn.pt
â”‚   â”‚   â”‚   â”œâ”€â”€ train_human_enhancers_ensembl.pt
â”‚   â”‚   â”‚   â”œâ”€â”€ train_human_ensembl_regulatory.pt
â”‚   â”‚   â”‚   â”œâ”€â”€ train_human_nontata_promoters.pt
â”‚   â”‚   â”‚   â””â”€â”€ train_human_ocr_ensembl.pt
â”‚   â”‚   â””â”€â”€ test.ipynb
â”‚   â””â”€â”€ dynamic_models
â”‚       â”œâ”€â”€ cdgpt
â”‚       â”‚   â”œâ”€â”€ result
â”‚       â”‚   â”‚   â””â”€â”€ C12_e2_1_6000_result_feature.pt
â”‚       â”‚   â””â”€â”€ train&valid
â”‚       â”‚       â”œâ”€â”€ cd_e2_step1_train&get_best_model.py
â”‚       â”‚       â””â”€â”€ cd_e2_step2_get_features.py
â”‚       â”œâ”€â”€ hyena
â”‚       â”‚   â”œâ”€â”€ result
â”‚       â”‚   â”‚   â””â”€â”€ C12_hyena_e2_140_result_feature.pt
â”‚       â”‚   â””â”€â”€ train&valid
â”‚       â”‚       â”œâ”€â”€ hy_e2_step1_train.py
â”‚       â”‚       â”œâ”€â”€ hy_e2_step2_get_best_model.py
â”‚       â”‚       â””â”€â”€ hy_e2_step3_get_features.py
â”‚       â”œâ”€â”€ ntv2
â”‚       â”‚   â”œâ”€â”€ result
â”‚       â”‚   â”‚   â””â”€â”€ C12_e2_ntv2_120_result_feature.pt
â”‚       â”‚   â””â”€â”€ train&valid
â”‚       â”‚       â”œâ”€â”€ nt_e2_get_best_model.py
â”‚       â”‚       â”œâ”€â”€ nt_e2_step1_train.py
â”‚       â”‚       â””â”€â”€ nt_e2_step3_get_features.py
â”‚       â”œâ”€â”€ step9
â”‚       â”‚   â”œâ”€â”€ cdgpt-e2-result-data-analysis
â”‚       â”‚   â”‚   â”œâ”€â”€ cd_0_right_file.pt
â”‚       â”‚   â”‚   â”œâ”€â”€ ......(omit 14 files)
â”‚       â”‚   â”‚   â””â”€â”€ nt_1_wrong_file.pt
â”‚       â”‚   â”œâ”€â”€ hyena-e2-result-data-analysis
â”‚       â”‚   â”‚   â”œâ”€â”€ cd_0_right_file.pt
â”‚       â”‚   â”‚   â”œâ”€â”€ ......(omit 14 files)
â”‚       â”‚   â”‚   â””â”€â”€ nt_1_wrong_file.pt
â”‚       â”‚   â””â”€â”€ ntv2-e2-result-data-analysis
â”‚       â”‚       â”œâ”€â”€ cd_0_right_file.pt
â”‚       â”‚       â”œâ”€â”€ ......(omit 14 files)
â”‚       â”‚       â””â”€â”€ nt_1_wrong_sequences.fasta
â”‚       â””â”€â”€ step9-result-data-processing.ipynb
â””â”€â”€ readme.md
```
